{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kpmurphy/github/shifty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 20:40:29.786225: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2022-10-10 20:40:30.169851: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-10 20:40:35.958474: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2022-10-10 20:40:35.958654: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2022-10-10 20:40:35.958665: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function logprior_fn at 0x7fa545132950>\n"
     ]
    }
   ],
   "source": [
    "%cd /home/kpmurphy/github/shifty\n",
    "#from shifty.skax.logreg_flax import *\n",
    "from shifty.skax.skax import *\n",
    "#from shifty.tta.tta import *\n",
    "from shifty.tta.gmm_data import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence WARNING:root:The use of `check_types` is deprecated and does not have any effect.\n",
    "# https://github.com/tensorflow/probability/issues/1523\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "class CheckTypesFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return \"check_types\" not in record.getMessage()\n",
    "\n",
    "\n",
    "logger.addFilter(CheckTypesFilter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "KeyboardInterrupt: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorDataset, DataLoader\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdistrax\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/__init__.py:202\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[39mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[1;32m    201\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 202\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39m# torch._C module initialization code in C\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: KeyboardInterrupt: "
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "import scipy.stats\n",
    "import einops\n",
    "from functools import partial\n",
    "\n",
    "from functools import partial\n",
    "from collections import namedtuple\n",
    "import itertools\n",
    "from itertools import repeat\n",
    "from time import time\n",
    "import chex\n",
    "import typing\n",
    "from typing import Any, Callable, Sequence\n",
    "\n",
    "import jax\n",
    "import jax.random as jr\n",
    "import jax.numpy as jnp\n",
    "from jax import vmap, grad, jit\n",
    "from jax import lax, random, numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "\n",
    "from flax.core import freeze, unfreeze\n",
    "from flax import linen as nn\n",
    "import flax\n",
    "\n",
    "import jaxopt\n",
    "import optax\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import distrax\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "tfd = tfp.distributions\n",
    "from tensorflow_probability.substrates.jax.distributions import MultivariateNormalFullCovariance as MVN\n",
    "\n",
    "#jax.config.update(\"jax_enable_x64\", False)\n",
    "\n",
    "\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1), TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0), TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1), TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0), TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1), TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0), TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "cpu_count = os.cpu_count()\n",
    "print(cpu_count)\n",
    "\n",
    "# Run jax on multiple CPU cores\n",
    "# https://github.com/google/jax/issues/5506\n",
    "# https://stackoverflow.com/questions/72328521/jax-pmap-with-multi-core-cpu\n",
    "import os \n",
    "#os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=90'\n",
    "\n",
    "import jax\n",
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shifty.tta.label_space import *\n",
    "from shifty.tta.data_generator import *\n",
    "from shifty.tta.tta import *\n",
    "from shifty.tta.estimators import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key = jr.PRNGKey(0)\n",
    "corr_source = 0.1\n",
    "corr_targets = jnp.arange(0.1, 0.9, step=0.1)\n",
    "ls = LabelSpace(nclasses=2, nfactors=2)\n",
    "src_dist = GMMDataGenerator(key, corr_source, ls, nfeatures=10, noise_factor=1)\n",
    "\n",
    "ntargets = ls.nclasses * ls.nfactors # network predicts joint output\n",
    "nhidden = (10,) + (ntargets,) # set nhidden = () + (ntargets,) to get logistic regression\n",
    "network = MLPNetwork(nhidden)\n",
    "mlp = NeuralNetClassifier(network, key, ntargets, l2reg=1e-5, optimizer = \"adam+warmup\", \n",
    "        batch_size=32, num_epochs=20, print_every=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kpmurphy/mambaforge/lib/python3.10/site-packages/distrax/_src/utils/conversion.py:143: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return x.astype(jnp.float_)\n"
     ]
    }
   ],
   "source": [
    "#estimator = OracleEstimator(ls)\n",
    "#estimator = UndaptedEstimator(mlp, ls)\n",
    "estimator = EMEstimator(mlp, ls)\n",
    "\n",
    "nsource_samples =500\n",
    "Xs, Ys, As = src_dist.sample(key, nsource_samples)\n",
    "estimator.fit_source(Xs, Ys, As, src_dist)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1  0.1  0.12 0.2  0.15 0.17 0.21 0.13]\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_estimator(key, src_dist, corr_targets, estimator)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1aafb1a5b8a6c5cc9d9564fe8ce376ad7cec1976d94f450e8b79a35770c931"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
